

# 1장 아파치 스파크 소개



## 1.1 스파크란?

* 고속 범용 분산 컴퓨팅 플랫폼
* 스파크는 하둡 맵리듀스 보다 10배에서 100배 더 빠른 속도로 같은 작업을 수행할 수 있다.
* 데이터 처리 작업에 적합한 함수형 프로그래밍도 사용할 수 있다.

#### 스파크가 가져온 혁명

* 하둡은 강력하지만 처리 속도가 다소 느릴 수 있다. 
* 이 속도문제를 해결한 것이 스파크이다. 
* **HDFS**와 **맵리듀스 처리 엔진**으로 구성된 하둡 프레임워크는 다음과 같은 3가지 문제를 해결했다.
  * 병렬처리(Parallelization) : 전체 연산을 잘게 나누어 동시에 처리하는 방법
  * 데이터 분산(distribution) : 데이터를 여러 노드로 분산하는 방법
  * 장애 내성(fault tolerance) : 분산 컴포넌트의 장애에 대응하는 방법 

#### 맵리듀스의 한계

* 하둡은 여전히 많이 쓰이고 강력하지만 한계가 있고 이 한계는 __맵리듀스__ 컴포넌트와 연관이 깊다.
  * 맵리듀스 잡의 결과를 다른 잡에서 사용하려면 먼저 이 결과를 HDFS에 저장해야함.
  * 따라서 본질적으로 이전 잡의 결과를 다음 작업이 입력이 되는 반복알고리즘에는 맞지 않다.
* 이를 해결하기위해 여러 도구들이 하둡에 부가해 환경을 더욱 복잡하게 만들었다.
* 하지만 스파크는 이런 문제를 상당부분 해결했다.



#### 스파크가 가져다 준 선물

* 스파크는 맵리듀스 처럼 잡에 필요한 데이터를 디스크에서 매번 가져오는 대신 데이터를 메모리에 캐시로 저장하는 __In-Memory__ 실행 모델에 있다.

  ![image](https://user-images.githubusercontent.com/55227984/132985110-cb9168ab-4d46-4818-af2d-09a7f7904ad7.png)

##### 사용 편의성

* 스파크는 파이썬, 스칼라를 포함한 여러 언어로 작성될 수 있다. 
* ![image](https://user-images.githubusercontent.com/55227984/132934112-6af5b122-3d0b-430b-ada1-151a0169730a.png)
* 특히, 데이터 분석에 적합한 함수형 프로그래밍 언어인 스칼라와 결합될 경우 더 유연하고 융통성있는 프로그램밍을 경험할 수 있다.
* 파이썬 처럼 REPL 을 이용해 간단한 테스트를 해볼 수 있고 전체 프로그램을 실행해 볼 수 도 있다.
* 유연하게 스파크 자체 클러스터 뿐만 아니라 하둡의 YARN, 아파치 메소스 클러스터 등 다양한 유형의 클러스터 매니저를 사용해 스파크를 실행 할 수 있다.
* 하둡 생태계의 여러 도구가 제공한 다양한 기능을 플랫폼 하나로 통합하였다. 



### 스파크로 구현할 수 있는 애플리케이션

* 일괄 처리 시스템
* 실시간 처리 시스템
* 스파크 job을 실행하는 웹 애플리케이션
* SQL을 사용한 정형 데이터 처리 시스템
* 기존 프로그래밍 기법을 사용한 비정형 데이터 처리 시스템
* 다양한 머신 러닝 및 데이터 개조 작업
* 다양한 분산 파일 시스템, 관계형 DB, NoSQL DB 실시간 시스템 등과 연동한 애플리케이션



#### 스파크로 구현해서는 안되는 애플리케이션

* 단일 머신에서도 충분히 처리할 수 있는 데이터셋을 다룰 때
  * Job 과 Task를 시작하는데 상당한 시간을 소요하기 때문에
* 온라인 트랜잭션 처리 애플리케이션을 사용 할 때
  * 대략의 원자성 트랜잭션을 빠르게 처리해야 하는 작업



## 1.2 스파크를 구성하는 컴포넌트

<img width="657" alt="Screen Shot 2021-09-11 at 12 03 32 PM" src="https://user-images.githubusercontent.com/55227984/132987881-6a2590c2-655a-4cbf-9f26-97eccac2b84d.png">





#### 스파크 코어

* __스파크 잡__, **스파크 컴포넌트**에 필요한 기본 기능 제공
* 스파크 코어에서 가장 중요한 개념은 __RDD(Resilient Distributed Dataset)__
  * __RDD__ 는 데이터셋을 추상화한 객체로 데이터셋에 적용할 수 있는 연산 및 변환 메서드를 함께 제공한다.
  * __RDD__ 는 노드에 장애가 발생해도 데이터셋을 재구성 할 수 있는 __복원성__ 갖춤
* 네트워킹, 보안, 스케줄링 및 데이터 셔플링 등 기본기능이 구현되어 있다.



#### 스파크SQL

* 스파크와 하이브 SQL 이 지원하는 SQL을 사용하여 대규모 분산 정형 데이터를 다룰 수 있는 기능 제공
* `DataFrame` 과 `Dataset` 은 정형 데이터의 처리를 __단순화__ 하고 __성능을 크게 개선__
* `DataFrame` 과 `Dataset` 에 적용된 연산을 일정 시점에 RDD 연산으로 변환해 스파크 잡으로 실행함
* 쿼리 최적화 도구로 `Catalyst` 라는 툴과 사용자가 직접 최적화 규칙을 적용해 프레임워크를 확장할 수도 있다.
* 외부 시스템과 스파크를 연동할 수 있는 아파치 쓰리프트 서버도 제공하며 외부 시스템은 기존의 JDBC, ODBC 를 사용해 스파크 SQL 쿼리 실행이 가능하다



#### 스파크 스트리밍

* 다양한 데이터 소스에서 유입되는 **실시간 스트리밍 데이터**를 처리하는 프레임 워크
* 장애가 발생하면 연산결과 자동 복구
* **이산 스트림** 방식으로 스트리밍 데이터를 표현하는데, 가장 마지막 타임 윈도우 안에 유입된 데이터를 RDD로 구성해 주기적으로 생성
* 스파크 버전 2.0 에서는 API의 도움으로 배치 처리 프로그램을 구현하는 것처럼 스트리밍 프로그램 구현 가능 
* 지원하는 스트리밍 소스
  * HDFS
  * 아파치 카프카
  * 트위터
  * ZeroMQ
  * 아파치 플럼



#### 스파크 MLlib

* 머신러닝 알고리즘 라이브러리
* 스파크 MLlib 를 사용해 RDD 또는 `DataFrame` 의 데이터셋을 변환하는 머신러닝모델을 구현 할 수 있음



#### 스파크 GraphX

* __그래프 RDD__ 형태의 그래프 구조를 만들 수 있는 다양한 기능을 제공함



## 1.3 스파크 프로그램의 실행과정

* 전제조건 : 300MB 크기의 로그 파일이 노드 3개로 구성된 HDFS 클러스터에 분산 저장 되어있음, HDSF 는 자동으로 128MB 크기의 청크로 분할 하고 각 블록을 클러스터의 여러 노드에 고르게 저장함. 사용자는 2주간 OOM 에러가 몇건이나 발생했는지 분석해달라는 요청을 받음

1. 스파크 쉘을 시작하고 스파크 클러스터를 연결해 다음과 같은 스칼라 명령을 입력해 HDFS에 저장된 로그파일을 메모리에 로드한다.

   ```scala
   val lines = sc.textFile("hdfs://path/to/the/file")
   ```

2. 스파크는 __데이터 지역성__ 을 최대한 달성하기 위해 로그 파일의 각 블록이 저장된 위치를 하둡에게 요청한 후, 모든 블록(데이터 파일) 을 클러스터 노드의 RAM 메모리로 전송한다. 

3. 데이터 전송이 완료 되면 스파크 쉘 에서 RAM 에 저장된 각 블록(파티션)을 참고할 수 있다. 

이 __블록__ 이 __RDD__ 가 참조하는 __분산 컬렉션__ 이며, 이 컬렉션에는 사용자가 분석해야할 로그 파일 줄이 저장되어있다. 

4. 사용자는 아래의 명령어를 입력해 OOM Error 문자열을 포함하지 않는 모든줄을 제거해 오류의 수를 계산할 수 있다.

   ```scala
   val oomLines = lines.filter(l => l.contains("OutOfMemoryError")).cache()
   ```

여기서 중요한점은 `oomLines` 를 캐시에 저장했으므로 스파크는 HDFS의 로그파일을 다시 로드하는 대신 캐시의 데이터를 재사용할 수 있다. 





## 1.4 스파크 생태계

![image](https://user-images.githubusercontent.com/55227984/132934479-6451f384-a7bf-4a3b-9a57-675fd232c6ef.png)

* 위의 그림은 하둡 생태계의 일부를 그린 내용이다.
* 스파크 컴포넌트의 기능과 하둡 생태계를 비교해보면 스파크가 일부도구를 대체할 수 있음을 할 수 있다.
  * 아파치 지라프 => 스파크 GraphX
  * 아파치 머하웃 => 스파크 MLlib
  * 아파치 스톰 => 스파크 스트리밍
  * 아파치 피그, 스쿱 => 스파크 코어, 스파크 SQL
* 아래와 같은 하둡의 생태계일부는 스파크 컴포넌트로 대체될 수 없다.
  * 우지: 다른 여러 유형의 하둡 잡을 스케줄링 하는데 사용(스파크 잡도 포함됨)
  * HBase : 스파크와는 완전 다른 성격의 대규모 분산 데이터베이스
  * 주키퍼 : 고성능 코디네이션 서비스(네이밍, 그룹 서비스 프로비저닝)
* etc
  * 아파치 임팔라와 드릴은 스파크와 공존할 수 있고 드릴은 실행엔진으로 스파크가 지원될 예정이다.
  * 임팔라와 드릴은 스파크의 코어와 SQL 기능을 포괄하기 때문에 스파크의 경쟁 프레임 워크에 가깝다.
  * YARN을 스파크에서는 실행할 필요가 없다.



## 요약

* 아파치 스파크는 하둡 맵리듀스를 대체할 빅데이터 처리 플랫폼이다.
* 아파치 스파크는 맵리듀스 프로그램보다 속도상 최대 100배 빠른 성능을 낼 수 있다.
* 스파크는 파이썬, 스칼라, 자바 등 여러 언어를 지원한다.
* 스파크로 분산 프로그램을 작성하는 것은 로컬에서 파이썬등의 프로그램을 작성하는 것과 매우 유사하다.
* 스파크는 다일 프레임워크에서 배치 처리기능, 실시간 데이터 처리 기능, SQL과 같은 정형 데이터 처리기능, 그래프 알고리즘 및 머신 러닝을 모두 지원하는 통함 플랫폼을 제공한다.
* 단, 소량의 데이터셋을 처리하는데는 오버헤드가 있기때문에 적합하지 않고  온라인 트랜잭션 처리에는 사용할 수 없다.
* RDD 는 스파크 분산 컬렉션의 추상화 객체이다.
* 스파크는 하둡의 일부 생태계를 대체할 수 있다.



## 추가설명

* 하둡 
  * __대용량 데이터를 분산 처리__ 할 수 있는 자바기반의 오픈소스프레임 워크
  * 분산시스템인 **`HDFS`**에 데이터를 저장하고 **`맵리듀스`**를 이용해 데이터를 처리한다.
  * 여러 대의 서버에 데이터를 저장하고, 저장된 각 서버에서 동시에 데이터를 처리하는 방식
  * 그렇다고 RDBMS를 대체하는 것이 아닌 협력하는 것
    * 하둡은 트랜잭션이나 무결성을 보장해야 하는 데이터 처리에 적합하지 않음
    * 배치성으로 데이터를 저장하고 처리하는데 적합한 시스템
    * Ex. RDBMS 에 저장해야 할 요소
      * 회원가입, 결재진행
    * Ex. 하둡에 저장해야할 요소
      * 회원의 이동경로, 머무르는 시간 등

* HDFS
  * `Hadoop FileSystem` 의 약자
  * 수십 TB 또는 PB 이상의 대용량 파일을 분산된 서버에 저장하고, 그 저장된 데이터를 빠르게 처리할 수 있게하는 파일 시스템
  * 저사양 서버를 이용해서 스토리지를 구성할 수 있다.
  * 파일을 특정크기의 블록으로 나누어 서버에 저장한다. 



* VAGRANT

  * 포터블 가상화 소프트웨어 개발 환경(도커 컨테이너, AWS, VirtualBox) 의 생성 및 유지보수를 위한 오픈소스 소프트웨어

  * 운영체제 시스템에 대하여 쉬운 Provisioning 을 할 수 있다. 

  * 대표적으로 VirtualBox 를 Vagrant를 사용하지 않고 만든다면 각각의 개별 가상머신을 생성하고 한대씩 설정해야 합니다.

  * CentOS를 설치 할 때 설치가 완료된 후에 ip 등을 설정하게 되는데 베이그런트를 사용하면 설치할 때 자동으로 정보를 다 가져가 세팅을 한번에 해준다.

    ![img](https://t1.daumcdn.net/cfile/tistory/99BE413A5B69D88202)

    

  * vagrant init 

    * 프로비저닝을 해주는 예제 스크립트 생성

   * vagrant up 

     * vagrantfile을 읽어 들여 프로비저닝 진행

   * vagrant halt  

     * 베이그런트에서 다루는 호스트들을 종료

   * vagrant destroy 

     * 베이그런드 호스트 삭제

   * vagrant ssh 

     * 베이그런트 호스트에 ssh 로 접속

   * vagrant provision 

     * 베이그런트의 호스트의 설정 변경 적용

  

## 질문

* Job 과 Task
  * ![spark-rdd-partitions-job-stage-tasks](https://rtfmplz.github.io/images/posts/what-is-job-stage-task-in-spark/spark-rdd-partitions-job-stage-tasks.png)
  * `Task(Command)`
    *  RDD의 각 파티션을 처리하기 위한 가장 작은 개별 실행 단위
    *  개별 파티션에 대한 연산을 처리하는 작업
    *  `JVM` 에 의해 실행
  * `Stage` 
    *  병렬 Task들의 집합, 물리적 실행단위
  * `Job` 
    * stage들을 분할한 계산들을 계산하는것 
    * `save` 나 `collect` 같은 스파크의 명령에 대한 응답으로 생성되고 다수의 task로 구성된 __병렬적인 계산__ 
* 그래서 Hadoop 은 어디에 사용이 될까?
  * 페이스북(Facebook)의 자동 이미지 검색(빠른 검색 결과 필요)
  * 페타바이트 단위의 데이터 클러스터들에서 결과를 찾아낼때 사용(Netflix)

