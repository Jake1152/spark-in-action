

# 1장 아파치 스파크 소개



## 1.1 스파크란?

* 고속 범용 분산 컴퓨팅 플랫폼
* 스파크는 하둡 맵리듀스 보다 10배에서 100배 더 빠른 속도로 같은 작업을 수행할 수 있다.
* 데이터 처리 작업에 적합한 함수형 프로그래밍도 사용할 수 있다.

#### 스파크가 가져온 혁명

* 하둡은 강력하지만 처리 속도가 다소 느릴 수 있다. 
* 이 속도문제를 해결한 것이 스파크이다. 
* __HDFS__와 __맵리듀스 처리 엔진__으로 구성된 하둡 프레임워크는 다음과 같은 3가지 문제를 해결했다.
  * 병렬처리(Parallelization) : 전체 연산을 잘게 나누어 동시에 처리하는 방법
  * 데이터 분산(distribution) : 데이터를 여러 노드로 분산하는 방법
  * 장애 내성(fault tolerance) : 분산 컴포넌트의 장애에 대응하는 방법 

#### 맵리듀스의 한계

* 하둡은 여전히 많이 쓰이고 강력하지만 한계가 있고 이 한계는 __맵리듀스__ 컴포넌트와 연관이 깊다.
  * 맵리듀스 잡의 결과를 다른 잡에서 사용하려면 먼저 이 결과를 HDFS에 저장해야함.
  * 따라서 본질적으로 이전 잡의 결과를 다음 작업이 입력이 되는 반복알고리즘에는 맞지 않다.
* 이를 해결하기위해 여러 도구들이 하둡에 부가해 환경을 더욱 복잡하게 만들었다.
* 하지만 스파크는 이런 문제를 상당부분 해결했다.



#### 스파크가 가져다 준 선물

* 스파크는 맵리듀스 처럼 잡에 필요한 데이터를 디스크에서 매번 가져오는 대신 데이터를 메모리에 캐시로 저장하는 __In-Memory__ 실행 모델에 있다.

##### 사용 편의성

* 스파크는 파이썬, 스칼라를 포함한 여러 언어로 작성될 수 있다. 
* ![image](https://user-images.githubusercontent.com/55227984/132934112-6af5b122-3d0b-430b-ada1-151a0169730a.png)
* 특히, 데이터 분석에 적합한 함수형 프로그래밍 언어인 스칼라와 결합될 경우 더 유연하고 융통성있는 프로그램밍을 경험할 수 있다.
* 파이썬 처럼 REPL 을 이용해 간단한 테스트를 해볼 수 있고 전체 프로그램을 실행해 볼 수 도 있다.
* 유연하게 스파크 자체 클러스터 뿐만 아니라 하둡의 YARN, 아파치 메소스 클러스터 등 다양한 유형의 클러스터 매니저를 사용해 스파크를 실행 할 수 있다.
* 하둡 생태계의 여러 도구가 제공한 다양한 기능을 플랫폼 하나로 통합하였다. 



### 스파크로 구현할 수 있는 애플리케이션

* 일괄 처리 시스템
* 실시간 처리 시스템
* 스파크 job을 실행하는 웹 애플리케이션
* SQL을 사용한 정형 데이터 처리 시스템
* 기존 프로그래밍 기법을 사용한 비정형 데이터 처리 시스템
* 다양한 머신 러닝 및 데이터 개조 작업
* 다양한 분산 파일 시스템, 관계형 DB, NoSQL DB 실시간 시스템 등과 연동한 애플리케이션



#### 스파크로 구현해서는 안되는 애플리케이션

* 단일 머신에서도 충분히 처리할 수 있는 데이터셋을 다룰 때
  * Job 과 Task를 시작하는데 상당한 시간을 소요하기 때문에
* 온라인 트랜잭션 처리 애플리케이션을 사용 할 때
  * 대략의 원자성 트랜잭션을 빠르게 처리해야 하는 작업



## 1.2 스파크를 구성하는 컴포넌트



![image-20210911120340795](/Users/nayeong-yun/Library/Application Support/typora-user-images/image-20210911120340795.png)



#### 스파크 코어

* __스파크 잡__, __스파크 컴포넌트__에 필요한 기본 기능 제공
* 스파크 코어에서 가장 중요한 개념은 __RDD(Resilient Distributed Dataset)__
  * __RDD__ 는 데이터셋을 추상화한 객체로 데이터셋에 적용할 수 있는 연산 및 변환 메서드를 함께 제공한다.
  * __RDD__ 는 노드에 장애가 발생해도 데이터셋을 재구성 할 수 있는 __복원성__ 갖춤
* 네트워킹, 보안, 스케줄링 및 데이터 셔플링 등 기본기능이 구현되어 있다.



#### 스파크SQL

* 스파크와 하이브 SQL 이 지원하는 SQL을 사용하여 대규모 분산 정형 데이터를 다룰 수 있는 기능 제공
* `DataFrame` 과 `Dataset` 은 정형 데이터의 처리를 __단순화__ 하고 __성능을 크게 개선__
* `DataFrame` 과 `Dataset` 에 적용된 연산을 일정 시점에 RDD 연산으로 변환해 스파크 잡으로 실행함
* 쿼리 최적화 도구로 `Catalyst` 라는 툴과 사용자가 직접 최적화 규칙을 적용해 프레임워크를 확장할 수도 있다.
* 외부 시스템과 스파크를 연동할 수 있는 아파치 쓰리프트 서버도 제공하며 외부 시스템은 기존의 JDBC, ODBC 를 사용해 스파크 SQL 쿼리 실행이 가능하다



#### 스파크 스트리밍

* 다양한 데이터 소스에서 유입되는 __실시간 스트리밍 데이터__를 처리하는 프레임 워크
* 장애가 발생하면 연산결과 자동 복구
* __이산 스트림__ 방식으로 스트리밍 데이터를 표현하는데, 가장 마지막 타임 윈도우 안에 유입된 데이터를 RDD로 구성해 주기적으로 생성
* 스파크 버전 2.0 에서는 API의 도움으로 배치 처리 프로그램을 구현하는 것처럼 스트리밍 프로그램 구현 가능 
* 지원하는 스트리밍 소스
  * HDFS
  * 아파치 카프카
  * 트위터
  * ZeroMQ
  * 아파치 플럼



#### 스파크 MLlib

* 머신러닝 알고리즘 라이브러리
* 스파크 MLlib 를 사용해 RDD 또는 `DataFrame` 의 데이터셋을 변환하는 머신러닝모델을 구현 할 수 있음



#### 스파크 GraphX

* __그래프 RDD__ 형태의 그래프 구조를 만들 수 있는 다양한 기능을 제공함



## 1.3 스파크 프로그램의 실행과정

* 전제조건 : 300MB 크기의 로그 파일이 노드 3개로 구성된 HDFS 클러스터에 분산 저장 되어있음, HDSF 는 자동으로 128MB 크기의 청크로 분할 하고 각 블록을 클러스터의 여러 노드에 고르게 저장함. 사용자는 2주간 OOM 에러가 몇건이나 발생했는지 분석해달라는 요청을 받음

1. 스파크 쉘을 시작하고 스파크 클러스터를 연결해 다음과 같은 스칼라 명령을 입력해 HDFS에 저장된 로그파일을 메모리에 로드한다.

   ```scala
   val lines = sc.textFile("hdfs://path/to/the/file")
   ```

2. 스파크는 __데이터 지역성__ 을 최대한 달성하기 위해 로그 파일의 각 블록이 저장된 위치를 하둡에게 요청한 후, 모든 블록(데이터 파일) 을 클러스터 노드의 RAM 메모리로 전송한다. 

3. 데이터 전송이 완료 되면 스파크 쉘 에서 RAM 에 저장된 각 블록(파티션)을 참고할 수 있다. 

이 __블록__ 이 __RDD__ 가 참조하는 __분산 컬렉션__ 이며, 이 컬렉션에는 사용자가 분석해야할 로그 파일 줄이 저장되어있다. 

4. 사용자는 아래의 명령어를 입력해 OOM Error 문자열을 포함하지 않는 모든줄을 제거해 오류의 수를 계산할 수 있다.

   ```scala
   val oomLines = lines.filter(l => l.contains("OutOfMemoryError")).cache()
   ```

여기서 중요한점은 `oomLines` 를 캐시에 저장했으므로 스파크는 HDFS의 로그파일을 다시 로드하는 대신 캐시의 데이터를 재사용할 수 있다. 





## 1.4 스파크 생태계

![image](https://user-images.githubusercontent.com/55227984/132934479-6451f384-a7bf-4a3b-9a57-675fd232c6ef.png)

* 위의 그림은 하둡 생태계의 일부를 그린 내용이다.
* 스파크 컴포넌트의 기능과 하둡 생태계를 비교해보면 스파크가 일부도구를 대체할 수 있음을 할 수 있다.
  * 아파치 지라프 => 스파크 GraphX
  * 아파치 머하웃 => 스파크 MLlib
  * 아파치 스톰 => 스파크 스트리밍
  * 아파치 피그, 스쿱 => 스파크 코어, 스파크 SQL
* 아래와 같은 하둡의 생태계일부는 스파크 컴포넌트로 대체될 수 없다.
  * 우지: 다른 여러 유형의 하둡 잡을 스케줄링 하는데 사용(스파크 잡도 포함됨)
  * HBase : 스파크와는 완전 다른 성격의 대규모 분산 데이터베이스
  * 주키퍼 : 고성능 코디네이션 서비스(네이밍, 그룹 서비스 프로비저닝)
* etc
  * 아파치 임팔라와 드릴은 스파크와 공존할 수 있고 드릴은 실행엔진으로 스파크가 지원될 예정이다.
  * 임팔라와 드릴은 스파크의 코어와 SQL 기능을 포괄하기 때문에 스파크의 경쟁 프레임 워크에 가깝다.
  * YARN을 스파크에서는 실행할 필요가 없다.



## 요약

* 아파치 스파크는 하둡 맵리듀스를 대체할 빅데이터 처리 플랫폼이다.
* 아파치 스파크는 맵리듀스 프로그램보다 속도상 최대 100배 빠른 성능을 낼 수 있다.
* 스파크는 파이썬, 스칼라, 자바 등 여러 언어를 지원한다.
* 스파크로 분산 프로그램을 작성하는 것은 로컬에서 파이썬등의 프로그램을 작성하는 것과 매우 유사하다.
* 스파크는 다일 프레임워크에서 배치 처리기능, 실시간 데이터 처리 기능, SQL과 같은 정형 데이터 처리기능, 그래프 알고리즘 및 머신 러닝을 모두 지원하는 통함 플랫폼을 제공한다.
* 단, 소량의 데이터셋을 처리하는데는 오버헤드가 있기때문에 적합하지 않고  온라인 트랜잭션 처리에는 사용할 수 없다.
* RDD 는 스파크 분산 컬렉션의 추상화 객체이다.
* 스파크는 하둡의 일부 생태계를 대체할 수 있다.
